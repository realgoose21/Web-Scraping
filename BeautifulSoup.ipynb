{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d691805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getfile\n",
    "import os\n",
    "import re\n",
    "from urllib import request\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "overlap = []\n",
    "url = \"https://www.eum.go.kr/web/in/pd/pdBoardList.jsp?subType=C&searchType=&searchWord=\"\n",
    "site = \"https://www.eum.go.kr\"\n",
    "rec = \"pdBoardDet.jsp;\"\n",
    "dl = \"/web/ac/DownloadBig.jsp?\"\n",
    "\n",
    "def get_download(url, fname, directory):\n",
    "    try:\n",
    "        os.chdir(directory)\n",
    "        request.urlretrieve(url, fname)\n",
    "        print('다운로드 완료\\n')\n",
    "    except HTTPError as e:\n",
    "        print('error')\n",
    "        return\n",
    "\n",
    "def downSearch(getDLATag, filename):\n",
    "   for getDLLink in getDLATag:\n",
    "       try:\n",
    "           if dl in getDLLink.get('href'):\n",
    "               accessDLUrl = site + getDLLink.get('href')\n",
    "               print(\"다운로드 링크: \", accessDLUrl)\n",
    "               path = \"C:\\\\PLAN\"\n",
    "               if os.path.isfile(path + filename):\n",
    "                   print(\"다운로드 실패 : 동일 파일 존재\\n\")\n",
    "               else:\n",
    "                   get_download(accessDLUrl, filename, path)\n",
    "       except:\n",
    "           pass\n",
    "\n",
    "def Search(getA, num):\n",
    "    for getLink in getA:\n",
    "        data = getLink.get('href')\n",
    "        try:\n",
    "            if rec in getLink.get(\"href\"):\n",
    "                if data not in overlap:\n",
    "                    overlap.append(data)\n",
    "                    accessUrl = site + getLink.get(\"href\")\n",
    "                    r = requests.get(accessUrl)\n",
    "                    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                    getDLATag = soup.find_all(\"a\")\n",
    "                    getfilenameTag = soup.find_all(\"td\")\n",
    "                    td = getfilenameTag[len(getfilenameTag)-1]\n",
    "                    filename = str(num) + \". \" + str(td)[4:int(str(td).find(\".pdf\"))+4].strip()\n",
    "                    #print(filename)\n",
    "                    num = num - 1\n",
    "                    downSearch(getDLATag, filename)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def main():\n",
    "    pageNo = 1\n",
    "    num = 14\n",
    "    while pageNo <= 14:\n",
    "        # request 모듈을 사용하여 웹 페이지의 내용을 가져온다\n",
    "        r = requests.get(url+str(pageNo))\n",
    "\n",
    "        # beautiful soup 초기화\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        # 태그로 찾기 (모든 항목)\n",
    "        getA = soup.find_all(\"a\")\n",
    "        Search(getA, num)\n",
    "\n",
    "        pageNo += 1\n",
    "        num -= 1\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
